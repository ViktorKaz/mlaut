{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "from mlaut.data import Data\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = 'd2b1d13981d4abfb22895337baca924c'\n",
    "openml.config.apikey = apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_tasks = openml.tasks.list_tasks(task_type_id=1)\n",
    "regression_tasks = openml.tasks.list_tasks(task_type_id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()\n",
    "input_io = data.open_hdf5('data/openml.h5', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset 45 could not be downloaded\n",
      "dataset 47 could not be downloaded\n",
      "dataset 58 could not be downloaded\n",
      "dataset 219 could not be downloaded\n",
      "dataset 220 could not be downloaded\n",
      "dataset 221 could not be downloaded\n",
      "dataset 233 could not be downloaded\n",
      "dataset 234 could not be downloaded\n",
      "dataset 235 could not be downloaded\n",
      "dataset 236 could not be downloaded\n",
      "dataset 237 could not be downloaded\n",
      "dataset 238 could not be downloaded\n",
      "dataset 239 could not be downloaded\n",
      "dataset 240 could not be downloaded\n",
      "dataset 241 could not be downloaded\n",
      "dataset 242 could not be downloaded\n",
      "dataset 243 could not be downloaded\n"
     ]
    }
   ],
   "source": [
    "for id in classification_tasks.keys():\n",
    "    try:\n",
    "        print(f'savind dataset: {id}')\n",
    "        dataset = openml.datasets.get_dataset(id)\n",
    "        X, names = dataset.get_data(return_attribute_names=True)\n",
    "\n",
    "        #ignore datasets with empty values\n",
    "        num_missing_values = dataset.__dict__['qualities']['NumberOfMissingValues']\n",
    "        if num_missing_values is not 0:\n",
    "            continue\n",
    "\n",
    "        metadata = {\n",
    "            'class_name': dataset.__dict__['default_target_attribute'],\n",
    "            'source': 'OpenML',\n",
    "            'dataset_name':dataset.__dict__['name']\n",
    "        }\n",
    "        class_name_index = names.index(metadata['class_name'])\n",
    "\n",
    "        #Normalize the data\n",
    "        scaler = preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "        scaler.fit(X)\n",
    "        x_transformed  = scaler.transform(X)\n",
    "        x_transformed[:,class_name_index] = X[:, class_name_index]\n",
    "\n",
    "        #Convert to DataFrame\n",
    "        result = pd.DataFrame(x_transformed)\n",
    "        result.columns=names\n",
    "        result[metadata['class_name']] =  result[metadata['class_name']].astype(int)\n",
    "\n",
    "        #save to hdf5\n",
    "        input_io.save_pandas_dataset(dataset=result, save_loc='/openml', metadata=metadata)\n",
    "    except:\n",
    "        print(f'dataset {id} could not be downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dts = openml.datasets.get_dataset(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_tasks[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, names = dts.get_data(return_attribute_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts.__dict__['qualities']['NumberOfMissingValues']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
