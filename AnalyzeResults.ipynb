{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mlaut.analyze_results import AnalyseResults\n",
    "from mlaut.data import Data\n",
    "import pandas as pd\n",
    "from mlaut.estimators.estimators import instantiate_default_estimators\n",
    "from mlaut.analyze_results.scores import ScoreAccuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 50\n",
    "import Orange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()\n",
    "input_io = data.open_hdf5('data/delgado.h5', mode='r')\n",
    "out_io = data.open_hdf5('data/delgado-classification-deep.h5', mode='r')\n",
    "analyze = AnalyseResults(hdf5_output_io=out_io, \n",
    "                        hdf5_input_io=input_io, \n",
    "                        input_h5_original_datasets_group='openml/', \n",
    "                        output_h5_predictions_group='experiments/predictions/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlaut.estimators.nn_estimators import Deep_NN_Classifier\n",
    "hyperparameters = {'epochs': [50,100], \n",
    "                    'batch_size': [0, 50, 100]}\n",
    "def keras_model1(num_classes, input_dim):\n",
    "    model = OverwrittenSequentialClassifier()\n",
    "    model.add(Dense(288, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(144, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "deep_nn_4_layer_thin_dropout = Deep_NN_Classifier(keras_model=keras_model1, \n",
    "                            properties={'name':'NN-4-layer_thin_dropout'})\n",
    "\n",
    "\n",
    "def keras_model2(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dense(2500, input_dim=input_dim, activation='relu'))\n",
    "    nn_deep_model.add(Dense(2000, activation='relu'))\n",
    "    nn_deep_model.add(Dense(1500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=0.001)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "\n",
    "deep_nn_4_layer_wide_no_dropout = Deep_NN_Classifier(hyperparameters=hyperparameters,\n",
    "                            keras_model=keras_model2,\n",
    "                            properties={'name':'NN-4-layer_wide_no_dropout'})\n",
    "\n",
    "\n",
    "def keras_model3(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dense(2500, input_dim=input_dim, activation='relu'))\n",
    "    nn_deep_model.add(Dense(2000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(1500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=0.001)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "\n",
    "deep_nn_4_layer_wide_with_dropout = Deep_NN_Classifier(hyperparameters=hyperparameters,\n",
    "                            keras_model=keras_model3,\n",
    "                            properties={'name':'NN-4-layer_wide_with_dropout'})\n",
    "\n",
    "\n",
    "def keras_model4(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dense(5000, input_dim=input_dim, activation='relu'))\n",
    "    nn_deep_model.add(Dense(4500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(4000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "\n",
    "    nn_deep_model.add(Dense(3500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(3000, activation='relu'))\n",
    "    nn_deep_model.add(Dense(2500, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "    nn_deep_model.add(Dense(2000, activation='relu'))\n",
    "    nn_deep_model.add(Dense(1500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(1000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "\n",
    "    nn_deep_model.add(Dense(500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(250, activation='relu'))\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=0.001)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "\n",
    "deep_nn_12_layer_wide_with_dropout = Deep_NN_Classifier(hyperparameters=hyperparameters,\n",
    "                            keras_model=keras_model4,\n",
    "                            properties={'name':'NN-12-layer_wide_with_dropout'})\n",
    "\n",
    "\n",
    "\n",
    "def keras_model_1_lr01(num_classes, input_dim):\n",
    "    model = OverwrittenSequentialClassifier()\n",
    "    model.add(Dense(288, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(144, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=0.1)\n",
    "    model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "deep_nn_4_layer_thin_dropout_lr01 = Deep_NN_Classifier(keras_model=keras_model_1_lr01, \n",
    "                            properties={'name':'NN-4-layer_thin_dropout_lr01'})\n",
    "\n",
    "def keras_model_1_lr1(num_classes, input_dim):\n",
    "    model = OverwrittenSequentialClassifier()\n",
    "    model.add(Dense(288, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(144, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=1)\n",
    "    model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "deep_nn_4_layer_thin_dropout_lr1 = Deep_NN_Classifier(keras_model=keras_model_1_lr1, \n",
    "                            properties={'name':'NN-4-layer_thin_dropout_lr1'})\n",
    "\n",
    "\n",
    "def keras_model_2_lr01(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dense(2500, input_dim=input_dim, activation='relu'))\n",
    "    nn_deep_model.add(Dense(2000, activation='relu'))\n",
    "    nn_deep_model.add(Dense(1500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=0.1)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "\n",
    "deep_nn_4_layer_wide_no_dropout_lr01 = Deep_NN_Classifier(keras_model=keras_model_2_lr01,\n",
    "                            properties={'name':'NN-4-layer_wide_no_dropout_lr01'})\n",
    "\n",
    "\n",
    "def keras_model_2_lr1(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dense(2500, input_dim=input_dim, activation='relu'))\n",
    "    nn_deep_model.add(Dense(2000, activation='relu'))\n",
    "    nn_deep_model.add(Dense(1500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=1)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "\n",
    "deep_nn_4_layer_wide_no_dropout_lr1 = Deep_NN_Classifier(keras_model=keras_model_2_lr1,\n",
    "                            properties={'name':'NN-4-layer_wide_no_dropout_lr1'})\n",
    "\n",
    "\n",
    "\n",
    "def keras_model_3_lr01(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dense(2500, input_dim=input_dim, activation='relu'))\n",
    "    nn_deep_model.add(Dense(2000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(1500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=0.1)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "\n",
    "deep_nn_4_layer_wide_with_dropout_lr01 = Deep_NN_Classifier(keras_model=keras_model_3_lr01,\n",
    "                            properties={'name':'NN-4-layer_wide_with_dropout_lr01'})\n",
    "\n",
    "\n",
    "def keras_model_3_lr1(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dense(2500, input_dim=input_dim, activation='relu'))\n",
    "    nn_deep_model.add(Dense(2000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(1500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=1)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "\n",
    "deep_nn_4_layer_wide_with_dropout_lr1 = Deep_NN_Classifier(keras_model=keras_model_3_lr1,\n",
    "                            properties={'name':'NN-4-layer_wide_with_dropout_lr1'})\n",
    "\n",
    "\n",
    "\n",
    "def keras_model_4_lr01(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dense(5000, input_dim=input_dim, activation='relu'))\n",
    "    nn_deep_model.add(Dense(4500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(4000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "\n",
    "    nn_deep_model.add(Dense(3500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(3000, activation='relu'))\n",
    "    nn_deep_model.add(Dense(2500, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    \n",
    "    \n",
    "    nn_deep_model.add(Dense(2000, activation='relu'))\n",
    "    nn_deep_model.add(Dense(1500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(1000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    \n",
    "    nn_deep_model.add(Dense(500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(250, activation='relu'))\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model_optimizer = optimizers.Adam(lr=0.1)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "\n",
    "deep_nn_12_layer_wide_with_dropout_lr01 = Deep_NN_Classifier(keras_model=keras_model_4_lr01,\n",
    "                            properties={'name':'NN-12-layer_wide_with_dropout_lr01'})\n",
    "\n",
    "def keras_model_4_lr1(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dense(5000, input_dim=input_dim, activation='relu'))\n",
    "    nn_deep_model.add(Dense(4500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(4000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "\n",
    "    nn_deep_model.add(Dense(3500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(3000, activation='relu'))\n",
    "    nn_deep_model.add(Dense(2500, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    \n",
    "    \n",
    "    nn_deep_model.add(Dense(2000, activation='relu'))\n",
    "    nn_deep_model.add(Dense(1500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(1000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    \n",
    "    nn_deep_model.add(Dense(500, activation='relu'))\n",
    "    nn_deep_model.add(Dense(250, activation='relu'))\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model_optimizer = optimizers.Adam(lr=1)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "\n",
    "deep_nn_12_layer_wide_with_dropout_lr1 = Deep_NN_Classifier(keras_model=keras_model_4_lr1,\n",
    "                            properties={'name':'NN-12-layer_wide_with_dropout_lr1'})\n",
    "\n",
    "def keras_model_5_lr0001(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dense(2000, input_dim=input_dim, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(1000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(1000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(50, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=0.001)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "deep_nn_4_layer_droput_each_layer_lr0001 = Deep_NN_Classifier(keras_model=keras_model_5_lr0001,\n",
    "                                        properties={'name':'NN-4-layer-droput-each-layer_lr0001'})\n",
    "\n",
    "def keras_model_5_lr01(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dense(2000, input_dim=input_dim, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(1000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(1000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(50, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=0.1)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "deep_nn_4_layer_droput_each_layer_lr01 = Deep_NN_Classifier(keras_model=keras_model_5_lr01,\n",
    "                                        properties={'name':'NN-4-layer-droput-each-layer_lr01'})\n",
    "\n",
    "def keras_model_5_lr1(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dense(2000, input_dim=input_dim, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(1000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(1000, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(50, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=1)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "deep_nn_4_layer_droput_each_layer_lr1 = Deep_NN_Classifier(keras_model=keras_model_5_lr01,\n",
    "                                        properties={'name':'NN-4-layer-droput-each-layer_lr1'})\n",
    "\n",
    "def keras_model_6_lr001(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dropout(0.7, input_shape=(input_dim,)))\n",
    "    nn_deep_model.add(Dense(1024, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=0.001)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "deep_nn_2_layer_droput_input_layer_lr001 = Deep_NN_Classifier(keras_model=keras_model_6_lr001,\n",
    "                                        properties={'name':'NN-2-layer-droput-input-layer_lr001'})\n",
    "\n",
    "def keras_model_6_lr01(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dropout(0.7, input_shape=(input_dim,)))\n",
    "    nn_deep_model.add(Dense(1024, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=0.1)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "deep_nn_2_layer_droput_input_layer_lr01 = Deep_NN_Classifier(keras_model=keras_model_6_lr01,\n",
    "                                        properties={'name':'NN-2-layer-droput-input-layer_lr01'})\n",
    "\n",
    "def keras_model_6_lr1(num_classes, input_dim):\n",
    "    nn_deep_model = OverwrittenSequentialClassifier()\n",
    "    nn_deep_model.add(Dropout(0.7, input_shape=(input_dim,)))\n",
    "    nn_deep_model.add(Dense(1024, activation='relu'))\n",
    "    nn_deep_model.add(Dropout(0.5))\n",
    "    nn_deep_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model_optimizer = optimizers.Adam(lr=1)\n",
    "    nn_deep_model.compile(loss='mean_squared_error', optimizer=model_optimizer, metrics=['accuracy'])\n",
    "    return nn_deep_model\n",
    "\n",
    "deep_nn_2_layer_droput_input_layer_lr1 = Deep_NN_Classifier(keras_model=keras_model_6_lr1,\n",
    "                                        properties={'name':'NN-2-layer-droput-input-layer_lr1'})\n",
    "\n",
    "estimators = [deep_nn_4_layer_thin_dropout_lr01,\n",
    "            deep_nn_4_layer_thin_dropout_lr1, \n",
    "            deep_nn_4_layer_wide_no_dropout_lr01,\n",
    "            deep_nn_4_layer_wide_no_dropout_lr1,\n",
    "            deep_nn_4_layer_wide_with_dropout_lr01,\n",
    "            deep_nn_4_layer_wide_with_dropout_lr1,\n",
    "            deep_nn_12_layer_wide_with_dropout_lr01,\n",
    "            deep_nn_12_layer_wide_with_dropout_lr1,\n",
    "            deep_nn_4_layer_droput_each_layer_lr0001,\n",
    "            deep_nn_4_layer_droput_each_layer_lr01,\n",
    "            deep_nn_4_layer_droput_each_layer_lr1,\n",
    "            deep_nn_4_layer_thin_dropout,\n",
    "            deep_nn_4_layer_wide_no_dropout, \n",
    "            deep_nn_4_layer_wide_with_dropout,\n",
    "            deep_nn_12_layer_wide_with_dropout,            \n",
    "              deep_nn_2_layer_droput_input_layer_lr001,\n",
    "            deep_nn_2_layer_droput_input_layer_lr01,\n",
    "            deep_nn_2_layer_droput_input_layer_lr1]\n",
    "\n",
    "estim = instantiate_default_estimators(['Classification'])\n",
    "# estimators = []\n",
    "for e in estim:\n",
    "    if e.properties['name'] is not 'NeuralNetworkDeepClassifier':\n",
    "        estimators.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Predictions for estimator NN-4-layer_thin_dropout_lr01 unavailable for dataset: abalone. Analyse Results will skip abalone.\n",
      "WARNING:root:Predictions for estimator NN-4-layer_thin_dropout_lr1 unavailable for dataset: abalone. Analyse Results will skip abalone.\n",
      "WARNING:root:Predictions for estimator NN-12-layer_wide_with_dropout_lr01 unavailable for dataset: abalone. Analyse Results will skip abalone.\n",
      "WARNING:root:Predictions for estimator NN-12-layer_wide_with_dropout_lr1 unavailable for dataset: abalone. Analyse Results will skip abalone.\n",
      "WARNING:root:Predictions for estimator K_Neighbours unavailable for dataset: balloons. Analyse Results will skip balloons.\n",
      "WARNING:root:Predictions for estimator NN-12-layer_wide_with_dropout_lr01 unavailable for dataset: breast_cancer_wisc_prog. Analyse Results will skip breast_cancer_wisc_prog.\n",
      "WARNING:root:Predictions for estimator K_Neighbours unavailable for dataset: lenses. Analyse Results will skip lenses.\n",
      "WARNING:root:Predictions for estimator K_Neighbours unavailable for dataset: lung_cancer. Analyse Results will skip lung_cancer.\n",
      "WARNING:root:Predictions for estimator NN-12-layer_wide_with_dropout_lr01 unavailable for dataset: monks_2. Analyse Results will skip monks_2.\n",
      "WARNING:root:Predictions for estimator NN-12-layer_wide_with_dropout unavailable for dataset: semeion. Analyse Results will skip semeion.\n",
      "WARNING:root:Predictions for estimator K_Neighbours unavailable for dataset: trains. Analyse Results will skip trains.\n",
      "WARNING:root:Predictions for estimator NN-12-layer_wide_with_dropout_lr01 unavailable for dataset: twonorm. Analyse Results will skip twonorm.\n"
     ]
    }
   ],
   "source": [
    "# estimators = instantiate_default_estimators(['Classification'])\n",
    "score_accuracy = ScoreAccuracy()\n",
    "\n",
    "# (errors_per_estimator, \n",
    "#  errors_per_dataset_per_estimator) = analyze.prediction_errors(metric=score_accuracy, estimators=estimators)\n",
    " \n",
    "(errors_per_estimator, \n",
    " errors_per_dataset_per_estimator, \n",
    " errors_per_dataset_per_estimator_df) = analyze.prediction_errors(score_accuracy, estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple average and standard error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_score</th>\n",
       "      <th>std_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BaselineClassifier</th>\n",
       "      <td>0.419</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-12-layer_wide_with_dropout_lr1</th>\n",
       "      <td>0.458</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_thin_dropout_lr1</th>\n",
       "      <td>0.462</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_wide_with_dropout_lr01</th>\n",
       "      <td>0.478</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-12-layer_wide_with_dropout_lr01</th>\n",
       "      <td>0.479</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer-droput-each-layer_lr01</th>\n",
       "      <td>0.482</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_wide_with_dropout_lr1</th>\n",
       "      <td>0.483</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer-droput-each-layer_lr1</th>\n",
       "      <td>0.488</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_wide_no_dropout_lr1</th>\n",
       "      <td>0.490</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_wide_no_dropout_lr01</th>\n",
       "      <td>0.494</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_thin_dropout_lr01</th>\n",
       "      <td>0.494</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-2-layer-droput-input-layer_lr1</th>\n",
       "      <td>0.509</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-12-layer_wide_with_dropout</th>\n",
       "      <td>0.535</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-2-layer-droput-input-layer_lr01</th>\n",
       "      <td>0.543</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_thin_dropout</th>\n",
       "      <td>0.652</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-2-layer-droput-input-layer_lr001</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer-droput-each-layer_lr0001</th>\n",
       "      <td>0.662</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNaiveBayes</th>\n",
       "      <td>0.674</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_wide_with_dropout</th>\n",
       "      <td>0.692</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_wide_no_dropout</th>\n",
       "      <td>0.694</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNaiveBayes</th>\n",
       "      <td>0.707</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.758</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.790</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K_Neighbours</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     avg_score  std_error\n",
       "BaselineClassifier                       0.419      0.019\n",
       "NN-12-layer_wide_with_dropout_lr1        0.458      0.023\n",
       "NN-4-layer_thin_dropout_lr1              0.462      0.023\n",
       "NN-4-layer_wide_with_dropout_lr01        0.478      0.022\n",
       "NN-12-layer_wide_with_dropout_lr01       0.479      0.022\n",
       "NN-4-layer-droput-each-layer_lr01        0.482      0.022\n",
       "NN-4-layer_wide_with_dropout_lr1         0.483      0.022\n",
       "NN-4-layer-droput-each-layer_lr1         0.488      0.022\n",
       "NN-4-layer_wide_no_dropout_lr1           0.490      0.022\n",
       "NN-4-layer_wide_no_dropout_lr01          0.494      0.022\n",
       "NN-4-layer_thin_dropout_lr01             0.494      0.024\n",
       "NN-2-layer-droput-input-layer_lr1        0.509      0.023\n",
       "NN-12-layer_wide_with_dropout            0.535      0.023\n",
       "NN-2-layer-droput-input-layer_lr01       0.543      0.023\n",
       "NN-4-layer_thin_dropout                  0.652      0.022\n",
       "NN-2-layer-droput-input-layer_lr001      0.655      0.021\n",
       "NN-4-layer-droput-each-layer_lr0001      0.662      0.022\n",
       "GaussianNaiveBayes                       0.674      0.019\n",
       "NN-4-layer_wide_with_dropout             0.692      0.021\n",
       "NN-4-layer_wide_no_dropout               0.694      0.021\n",
       "BernoulliNaiveBayes                      0.707      0.015\n",
       "PassiveAggressiveClassifier              0.758      0.016\n",
       "GradientBoostingClassifier               0.790      0.016\n",
       "K_Neighbours                             0.805      0.014\n",
       "SVC                                      0.818      0.014\n",
       "BaggingClassifier                        0.820      0.014\n",
       "RandomForestClassifier                   0.831      0.013"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_and_std_error = analyze.average_and_std_error(errors_per_estimator)\n",
    "# avg_and_std_error.index.name='Estimator Name'\n",
    "avg_and_std_error.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K_Neighbours</th>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_wide_with_dropout</th>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_wide_no_dropout</th>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNaiveBayes</th>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer-droput-each-layer_lr0001</th>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_thin_dropout</th>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-2-layer-droput-input-layer_lr001</th>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNaiveBayes</th>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-12-layer_wide_with_dropout</th>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-2-layer-droput-input-layer_lr01</th>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-2-layer-droput-input-layer_lr1</th>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_thin_dropout_lr01</th>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_wide_no_dropout_lr01</th>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer-droput-each-layer_lr1</th>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_wide_with_dropout_lr1</th>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_wide_no_dropout_lr1</th>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_wide_with_dropout_lr01</th>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer-droput-each-layer_lr01</th>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-12-layer_wide_with_dropout_lr01</th>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-12-layer_wide_with_dropout_lr1</th>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN-4-layer_thin_dropout_lr1</th>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineClassifier</th>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     avg_rank\n",
       "RandomForestClassifier                    4.3\n",
       "SVC                                       5.0\n",
       "K_Neighbours                              5.6\n",
       "BaggingClassifier                         5.8\n",
       "GradientBoostingClassifier                7.6\n",
       "PassiveAggressiveClassifier               8.5\n",
       "NN-4-layer_wide_with_dropout             10.0\n",
       "NN-4-layer_wide_no_dropout               10.5\n",
       "BernoulliNaiveBayes                      10.9\n",
       "NN-4-layer-droput-each-layer_lr0001      11.2\n",
       "NN-4-layer_thin_dropout                  11.6\n",
       "NN-2-layer-droput-input-layer_lr001      11.7\n",
       "GaussianNaiveBayes                       13.4\n",
       "NN-12-layer_wide_with_dropout            16.3\n",
       "NN-2-layer-droput-input-layer_lr01       17.3\n",
       "NN-2-layer-droput-input-layer_lr1        17.9\n",
       "NN-4-layer_thin_dropout_lr01             18.0\n",
       "NN-4-layer_wide_no_dropout_lr01          18.4\n",
       "NN-4-layer-droput-each-layer_lr1         18.5\n",
       "NN-4-layer_wide_with_dropout_lr1         18.5\n",
       "NN-4-layer_wide_no_dropout_lr1           18.6\n",
       "NN-4-layer_wide_with_dropout_lr01        18.7\n",
       "NN-4-layer-droput-each-layer_lr01        18.8\n",
       "NN-12-layer_wide_with_dropout_lr01       18.8\n",
       "NN-12-layer_wide_with_dropout_lr1        19.0\n",
       "NN-4-layer_thin_dropout_lr1              19.4\n",
       "BaselineClassifier                       23.7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rank = analyze.ranks(errors_per_estimator, ascending=False)\n",
    "avg_rank.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks= avg_rank['avg_rank'].tolist()\n",
    "names = avg_rank.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = []\n",
    "rs = []\n",
    "first_nn_found = False\n",
    "\n",
    "for r,n in zip(ranks,names):\n",
    "    if n.startswith('NN') and first_nn_found == False:\n",
    "        ns.append(n)\n",
    "        rs.append(r)\n",
    "        first_nn_found = True\n",
    "    else:\n",
    "        if not n.startswith('NN'):\n",
    "            ns.append(n)\n",
    "            rs.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd = Orange.evaluation.compute_CD(rs,121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAADTCAYAAAA1fe/WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElSyBjQJEmSQsaAJkmSFDJ/AVliL/OTImCJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee62c27630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Orange.evaluation.graph_ranks(avranks=rs, names=ns, cd=cd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_training_time, training_time_per_dataset = analyze.average_training_time(estimators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge avg score, rank and training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_metrics = pd.DataFrame.merge(avg_rank,avg_and_std_error, left_index=True, right_index=True)\n",
    "avg_metrics = pd.DataFrame.merge(avg_metrics, avg_training_time,left_index=True, right_index=True)\n",
    "avg_metrics\n",
    "#change names of estimators\n",
    "as_list = avg_metrics.index.tolist()\n",
    "idx = as_list.index('NN-12-layer_wide_with_dropout')\n",
    "as_list[idx] = 'NN-12-layer_wide_with_dropout_lr001'\n",
    "\n",
    "idx = as_list.index('NN-4-layer_wide_with_dropout')\n",
    "as_list[idx] = 'NN-4-layer_wide_with_dropout_lr001'\n",
    "\n",
    "idx = as_list.index('NN-4-layer_wide_no_dropout')\n",
    "as_list[idx] = 'NN-4-layer_wide_no_dropout_lr001'\n",
    "\n",
    "\n",
    "idx = as_list.index('NN-4-layer_thin_dropout')\n",
    "as_list[idx] = 'NN-4-layer_thin_dropout_lr001'\n",
    "\n",
    "avg_metrics.index = as_list\n",
    "\n",
    "avg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cohen's d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cohens_d = analyze.cohens_d(errors_per_estimator)\n",
    "cohens_d.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_test, t_test_df = analyze.t_test(errors_per_estimator)\n",
    "t_test_df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_df.iloc[:,0:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sign test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_test, sign_test_df = analyze.sign_test(errors_per_estimator)\n",
    "sign_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-test with Bonferroni correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_test_bonferroni_df = analyze.t_test_with_bonferroni_correction(errors_per_estimator)\n",
    "t_test_bonferroni_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in estim:\n",
    "    print(e.properties['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wilcoxon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a, wilcoxon_df_multiindex = analyze.wilcoxon_test(errors_per_estimator)\n",
    "wilcoxon_df_multiindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Friedman test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, friedman_test_df = analyze.friedman_test(errors_per_estimator)\n",
    "friedman_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nemeniy_test = analyze.nemenyi(errors_per_estimator)\n",
    "nemeniy_test_df = pd.DataFrame(nemeniy_test)\n",
    "nemeniy_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "errors_per_dataset_per_estimator_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save tables to $\\LaTeX$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-test\n",
    "with open('../mlaut-paper/mlaut/tables/t_test.tex', 'w') as tf:\n",
    "    tf.write(t_test_df.to_latex())\n",
    "    \n",
    "t_test1 = t_test_df.iloc[:,0:8]\n",
    "t_test2 = t_test_df.iloc[:,8:16]\n",
    "t_test3 = t_test_df.iloc[:,16:24]\n",
    "t_test4 = t_test_df.iloc[:,24:32]\n",
    "t_test5 = t_test_df.iloc[:,32:40]\n",
    "t_test6 = t_test_df.iloc[:,40:48]\n",
    "t_test7 = t_test_df.iloc[:,48:54]\n",
    "\n",
    "with open('../mlaut-paper/mlaut/tables/t_test1.tex', 'w') as tf:\n",
    "    tf.write(t_test1.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/t_test2.tex', 'w') as tf:\n",
    "    tf.write(t_test2.to_latex()) \n",
    "with open('../mlaut-paper/mlaut/tables/t_test3.tex', 'w') as tf:\n",
    "    tf.write(t_test3.to_latex()) \n",
    "with open('../mlaut-paper/mlaut/tables/t_test4.tex', 'w') as tf:\n",
    "    tf.write(t_test4.to_latex()) \n",
    "with open('../mlaut-paper/mlaut/tables/t_test5.tex', 'w') as tf:\n",
    "    tf.write(t_test5.to_latex()) \n",
    "with open('../mlaut-paper/mlaut/tables/t_test6.tex', 'w') as tf:\n",
    "    tf.write(t_test6.to_latex()) \n",
    "with open('../mlaut-paper/mlaut/tables/t_test7.tex', 'w') as tf:\n",
    "    tf.write(t_test7.to_latex()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-test with Bonferroni\n",
    "with open('../mlaut-paper/mlaut/tables/t_test_bonferroni.tex', 'w') as tf:\n",
    "    tf.write(t_test_bonferroni_df.to_latex())\n",
    "    \n",
    "t_test_bonferroni1 = t_test_bonferroni_df.iloc[:,0:4]\n",
    "t_test_bonferroni2 = t_test_bonferroni_df.iloc[:,4:8]\n",
    "t_test_bonferroni3 = t_test_bonferroni_df.iloc[:,8:12]\n",
    "t_test_bonferroni4 = t_test_bonferroni_df.iloc[:,12:16]\n",
    "t_test_bonferroni5 = t_test_bonferroni_df.iloc[:,16:20]\n",
    "t_test_bonferroni6 = t_test_bonferroni_df.iloc[:,20:24]\n",
    "t_test_bonferroni7 = t_test_bonferroni_df.iloc[:,24:27]\n",
    "\n",
    "with open('../mlaut-paper/mlaut/tables/t_test_bonferroni1.tex', 'w') as tf:\n",
    "    tf.write(t_test_bonferroni1.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/t_test_bonferroni2.tex', 'w') as tf:\n",
    "    tf.write(t_test_bonferroni2.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/t_test_bonferroni3.tex', 'w') as tf:\n",
    "    tf.write(t_test_bonferroni3.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/t_test_bonferroni4.tex', 'w') as tf:\n",
    "    tf.write(t_test_bonferroni4.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/t_test_bonferroni5.tex', 'w') as tf:\n",
    "    tf.write(t_test_bonferroni5.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/t_test_bonferroni6.tex', 'w') as tf:\n",
    "    tf.write(t_test_bonferroni6.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/t_test_bonferroni7.tex', 'w') as tf:\n",
    "    tf.write(t_test_bonferroni7.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sign test\n",
    "with open('../mlaut-paper/mlaut/tables/sign_test.tex', 'w') as tf:\n",
    "    tf.write(sign_test_df.to_latex())\n",
    "sign_test1 = sign_test_df.iloc[:,0:8]\n",
    "sign_test2 = sign_test_df.iloc[:,8:16]\n",
    "sign_test3= sign_test_df.iloc[:,16:24]\n",
    "sign_test4 = sign_test_df.iloc[:,24:32]\n",
    "sign_test5 = sign_test_df.iloc[:,32:40]\n",
    "sign_test6 = sign_test_df.iloc[:,40:48]\n",
    "sign_test7 = sign_test_df.iloc[:,48:54]\n",
    "with open('../mlaut-paper/mlaut/tables/sign_test1.tex', 'w') as tf:\n",
    "    tf.write(sign_test1.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/sign_test2.tex', 'w') as tf:\n",
    "    tf.write(sign_test2.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/sign_test3.tex', 'w') as tf:\n",
    "    tf.write(sign_test3.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/sign_test4.tex', 'w') as tf:\n",
    "    tf.write(sign_test4.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/sign_test5.tex', 'w') as tf:\n",
    "    tf.write(sign_test5.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/sign_test6.tex', 'w') as tf:\n",
    "    tf.write(sign_test6.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/sign_test7.tex', 'w') as tf:\n",
    "    tf.write(sign_test7.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wilcoxon\n",
    "with open('../mlaut-paper/mlaut/tables/wilxocon_test.tex', 'w') as tf:\n",
    "    tf.write(wilcoxon_df_multiindex.to_latex())\n",
    "    \n",
    "wilcoxon1 = wilcoxon_df_multiindex.iloc[:,0:8]\n",
    "wilcoxon2 = wilcoxon_df_multiindex.iloc[:,8:16]\n",
    "wilcoxon3 = wilcoxon_df_multiindex.iloc[:,16:24]\n",
    "wilcoxon4 = wilcoxon_df_multiindex.iloc[:,24:32]\n",
    "wilcoxon5 = wilcoxon_df_multiindex.iloc[:,32:40]\n",
    "wilcoxon6 = wilcoxon_df_multiindex.iloc[:,40:48]\n",
    "wilcoxon7 = wilcoxon_df_multiindex.iloc[:,48:54]\n",
    "\n",
    "with open('../mlaut-paper/mlaut/tables/wilcoxon_test1.tex', 'w') as tf:\n",
    "    tf.write(wilcoxon1.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/wilcoxon_test2.tex', 'w') as tf:\n",
    "    tf.write(wilcoxon2.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/wilcoxon_test3.tex', 'w') as tf:\n",
    "    tf.write(wilcoxon3.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/wilcoxon_test4.tex', 'w') as tf:\n",
    "    tf.write(wilcoxon4.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/wilcoxon_test5.tex', 'w') as tf:\n",
    "    tf.write(wilcoxon5.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/wilcoxon_test6.tex', 'w') as tf:\n",
    "    tf.write(wilcoxon6.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/wilcoxon_test7.tex', 'w') as tf:\n",
    "    tf.write(wilcoxon7.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nemeniy test\n",
    "with open('../mlaut-paper/mlaut/tables/nemeniy_test.tex', 'w') as tf:\n",
    "    tf.write(nemeniy_test_df.to_latex())\n",
    "    \n",
    "nemeniy_test1 = nemeniy_test_df.iloc[:,0:4]\n",
    "nemeniy_test2 = nemeniy_test_df.iloc[:,4:8]\n",
    "nemeniy_test3 = nemeniy_test_df.iloc[:,8:12]\n",
    "nemeniy_test4 = nemeniy_test_df.iloc[:,12:16]\n",
    "nemeniy_test5 = nemeniy_test_df.iloc[:,16:20]\n",
    "nemeniy_test6 = nemeniy_test_df.iloc[:,20:24]\n",
    "nemeniy_test7 = nemeniy_test_df.iloc[:,24:27]\n",
    "\n",
    "with open('../mlaut-paper/mlaut/tables/nemeniy_test1.tex', 'w') as tf:\n",
    "    tf.write(nemeniy_test1.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/nemeniy_test2.tex', 'w') as tf:\n",
    "    tf.write(nemeniy_test2.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/nemeniy_test3.tex', 'w') as tf:\n",
    "    tf.write(nemeniy_test3.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/nemeniy_test4.tex', 'w') as tf:\n",
    "    tf.write(nemeniy_test4.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/nemeniy_test5.tex', 'w') as tf:\n",
    "    tf.write(nemeniy_test5.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/nemeniy_test6.tex', 'w') as tf:\n",
    "    tf.write(nemeniy_test6.to_latex())\n",
    "with open('../mlaut-paper/mlaut/tables/nemeniy_test7.tex', 'w') as tf:\n",
    "    tf.write(nemeniy_test7.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average and standard error\n",
    "with open('../mlaut-paper/mlaut/tables/avg_and_st_error.tex', 'w') as tf:\n",
    "    tf.write(avg_and_std_error.to_latex())\n",
    "#average trining time\n",
    "with open('../mlaut-paper/mlaut/tables/avg_training_time.tex', 'w') as tf:\n",
    "    tf.write(avg_training_time.to_latex())\n",
    "#average rank\n",
    "with open('../mlaut-paper/mlaut/tables/avg_rank.tex', 'w') as tf:\n",
    "    tf.write(avg_rank.to_latex())\n",
    "\n",
    "#average metrics\n",
    "with open('../mlaut-paper/mlaut/tables/avg_metrics.tex', 'w') as tf:\n",
    "    tf.write(avg_metrics.to_latex())\n",
    "#Cohen's D\n",
    "with open('../mlaut-paper/mlaut/tables/cohens_d.tex', 'w') as tf:\n",
    "    tf.write(cohens_d.to_latex())\n",
    "\n",
    "\n",
    "\n",
    "#Errors per dataset per estimator\n",
    "with open('../mlaut-paper/mlaut/tables/errors_per_dataset_per_estimator.tex', 'w') as tf:\n",
    "    tf.write(errors_per_dataset_per_estimator_df.to_latex(longtable=True))\n",
    "#              replace('\\n', '\\n\\\\caption{Errors per dataset and estimator}\\\\\\\\\\n', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../mlaut-paper/mlaut/tables/friedman_test.tex', 'w') as tf:\n",
    "    tf.write(friedman_test_df.to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
