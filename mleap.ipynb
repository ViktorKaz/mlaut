{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_delgado.delgado_datasets import DownloadAndConvertDelgadoDatasets\n",
    "from mleap.data import Data\n",
    "from mleap.data.estimators import instantiate_default_estimators\n",
    "from mleap.experiments import TestOrchestrator\n",
    "from mleap.analyze_results import AnalyseResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Dataset Delgado_data/molec-biol-protein-second has a different number of arff files\n"
     ]
    }
   ],
   "source": [
    "#load datasets as pandas DataFrame\n",
    "#each dataset needs to have metadata attached to it containing the following keys:\n",
    "# class_name: (string) name of column containing the column name in which the labels are stored\n",
    "# dataset_name: (string) name of the dataset\n",
    "delgado = DownloadAndConvertDelgadoDatasets()\n",
    "datasets, metadata = delgado.download_and_extract_datasets(verbose = False) #think about storing in hdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save the datasets in HDF5 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files io object needs to be used in test orch\n",
    "# returned object needs to be integrated in code\n",
    "data = Data()\n",
    "data.pandas_to_db(save_loc_hdf5='delgado_datasets/', datasets=datasets, \n",
    "                  dts_metadata=metadata, save_loc_hdd='data/delgado.hdf5') #return files io object\n",
    "input_io = data.open_hdf5('data/delgado.hdf5', mode='r')\n",
    "out_io = data.open_hdf5('data/experiments.hdf5', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Instantiate models and Test Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instantiated_models = instantiate_default_estimators()\n",
    "\n",
    "test_o = TestOrchestrator(hdf5_input_path='data/delgado.hdf5', hdf5_output_path='data/experiments.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dts_list = data.list_datasets(hdf5_io=input_io, hdf5_group='delgado_datasets/')\n",
    "split_dts_list = data.split_datasets(hdf5_in=input_io, hdf5_out=out_io, dataset_paths=dts_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Run the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training models on dataset: abalone. Total datasets processed: 0/3 ***\n",
      "*** Training models on dataset: acute_inflammation. Total datasets processed: 1/3 ***\n",
      "*** Training models on dataset: acute_nephritis. Total datasets processed: 2/3 ***\n"
     ]
    }
   ],
   "source": [
    "test_o.run(input_io_datasets_loc=dts_list[0:3], output_io_split_idx_loc=split_dts_list[0:3], modelling_strategies=instantiated_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze = AnalyseResults('data/experiments.hdf5')\n",
    "t_test, t_test_df = analyze.perform_t_test()\n",
    "print('******t-test******')\n",
    "print(t_test_df)\n",
    "\n",
    "sign_test, sign_test_df = analyze.perform_sign_test()\n",
    "print('******sign test******')\n",
    "print(sign_test_df)\n",
    "\n",
    "t_test_bonferroni, t_test_bonferroni_df = analyze.perform_t_test_with_bonferroni_correction()\n",
    "print('******t-test bonferroni correction******')\n",
    "print(t_test_bonferroni_df)\n",
    "wilcoxon_test, wilcoxon_test_df = analyze.perform_wilcoxon()\n",
    "print('******Wilcoxon test******')\n",
    "print(wilcoxon_test_df)\n",
    "\n",
    "friedman_test, friedman_test_df = analyze.perform_friedman_test()\n",
    "print('******Friedman test******')\n",
    "print(friedman_test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
