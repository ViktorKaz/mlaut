{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from download_delgado.delgado_datasets import DownloadAndConvertDelgadoDatasets\n",
    "from mleap.data import Data\n",
    "from mleap.estimators.estimators import instantiate_default_estimators\n",
    "from mleap.experiments import Orchestrator\n",
    "from mleap.analyze_results import AnalyseResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Dataset Delgado_data/molec-biol-protein-second has a different number of arff files\n"
     ]
    }
   ],
   "source": [
    "#load datasets as pandas DataFrame\n",
    "#each dataset needs to have metadata attached to it containing the following keys:\n",
    "# class_name: (string) name of column containing the column name in which the labels are stored\n",
    "# dataset_name: (string) name of the dataset\n",
    "delgado = DownloadAndConvertDelgadoDatasets()\n",
    "datasets, metadata = delgado.download_and_extract_datasets(verbose = False) #think about storing in hdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save the datasets in HDF5 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files io object needs to be used in test orch\n",
    "# returned object needs to be integrated in code\n",
    "data = Data()\n",
    "data.pandas_to_db(save_loc_hdf5='delgado_datasets/', datasets=datasets, \n",
    "                  dts_metadata=metadata, save_loc_hdd='data/delgado.hdf5') #return files io object\n",
    "input_io = data.open_hdf5('data/delgado.hdf5', mode='r')\n",
    "out_io = data.open_hdf5('data/classification.hdf5', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Instantiate models and Test Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instantiated_models = instantiate_default_estimators(estimators=['Generalized Linear Models'])\n",
    "\n",
    "test_o = TestOrchestrator(hdf5_input_io=input_io, hdf5_output_io=out_io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-06 23:29:38,452 [MainThread  ] [WARNI]  Skipping abalone as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,465 [MainThread  ] [WARNI]  Skipping acute_inflammation as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,476 [MainThread  ] [WARNI]  Skipping acute_nephritis as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,490 [MainThread  ] [WARNI]  Skipping adult as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,507 [MainThread  ] [WARNI]  Skipping annealing as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,527 [MainThread  ] [WARNI]  Skipping arrhythmia as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,545 [MainThread  ] [WARNI]  Skipping audiology_std as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,572 [MainThread  ] [WARNI]  Skipping balance_scale as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,596 [MainThread  ] [WARNI]  Skipping balloons as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,610 [MainThread  ] [WARNI]  Skipping bank as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,628 [MainThread  ] [WARNI]  Skipping blood as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,643 [MainThread  ] [WARNI]  Skipping breast_cancer as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,676 [MainThread  ] [WARNI]  Skipping breast_cancer_wisc as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,696 [MainThread  ] [WARNI]  Skipping breast_cancer_wisc_diag as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,713 [MainThread  ] [WARNI]  Skipping breast_cancer_wisc_prog as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,731 [MainThread  ] [WARNI]  Skipping breast_tissue as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,746 [MainThread  ] [WARNI]  Skipping car as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,763 [MainThread  ] [WARNI]  Skipping cardiotocography_10clases as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,782 [MainThread  ] [WARNI]  Skipping cardiotocography_3clases as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,801 [MainThread  ] [WARNI]  Skipping chess_krvk as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,818 [MainThread  ] [WARNI]  Skipping chess_krvkp as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,838 [MainThread  ] [WARNI]  Skipping congressional_voting as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,853 [MainThread  ] [WARNI]  Skipping conn_bench_sonar_mines_rocks as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,866 [MainThread  ] [WARNI]  Skipping conn_bench_vowel_deterding as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,895 [MainThread  ] [WARNI]  Skipping connect_4 as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,910 [MainThread  ] [WARNI]  Skipping contrac as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,932 [MainThread  ] [WARNI]  Skipping credit_approval as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,951 [MainThread  ] [WARNI]  Skipping cylinder_bands as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,974 [MainThread  ] [WARNI]  Skipping dermatology as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:38,996 [MainThread  ] [WARNI]  Skipping echocardiogram as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,015 [MainThread  ] [WARNI]  Skipping ecoli as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,032 [MainThread  ] [WARNI]  Skipping energy_y1 as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,053 [MainThread  ] [WARNI]  Skipping energy_y2 as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,068 [MainThread  ] [WARNI]  Skipping fertility as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,084 [MainThread  ] [WARNI]  Skipping flags as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,107 [MainThread  ] [WARNI]  Skipping glass as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,128 [MainThread  ] [WARNI]  Skipping haberman_survival as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,148 [MainThread  ] [WARNI]  Skipping hayes_roth as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,165 [MainThread  ] [WARNI]  Skipping heart_cleveland as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,184 [MainThread  ] [WARNI]  Skipping heart_hungarian as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,197 [MainThread  ] [WARNI]  Skipping heart_switzerland as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,208 [MainThread  ] [WARNI]  Skipping heart_va as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,222 [MainThread  ] [WARNI]  Skipping hepatitis as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,238 [MainThread  ] [WARNI]  Skipping hill_valley as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,250 [MainThread  ] [WARNI]  Skipping horse_colic as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,265 [MainThread  ] [WARNI]  Skipping ilpd_indian_liver as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,281 [MainThread  ] [WARNI]  Skipping image_segmentation as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,297 [MainThread  ] [WARNI]  Skipping ionosphere as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,320 [MainThread  ] [WARNI]  Skipping iris as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,340 [MainThread  ] [WARNI]  Skipping led_display as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,359 [MainThread  ] [WARNI]  Skipping lenses as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,381 [MainThread  ] [WARNI]  Skipping letter as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,406 [MainThread  ] [WARNI]  Skipping libras as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,424 [MainThread  ] [WARNI]  Skipping low_res_spect as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,448 [MainThread  ] [WARNI]  Skipping lung_cancer as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,464 [MainThread  ] [WARNI]  Skipping lymphography as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,480 [MainThread  ] [WARNI]  Skipping magic as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,499 [MainThread  ] [WARNI]  Skipping mammographic as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,554 [MainThread  ] [WARNI]  Skipping miniboone as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,578 [MainThread  ] [WARNI]  Skipping molec_biol_promoter as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,595 [MainThread  ] [WARNI]  Skipping molec_biol_splice as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,610 [MainThread  ] [WARNI]  Skipping monks_1 as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,628 [MainThread  ] [WARNI]  Skipping monks_2 as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,646 [MainThread  ] [WARNI]  Skipping monks_3 as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,666 [MainThread  ] [WARNI]  Skipping mushroom as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,680 [MainThread  ] [WARNI]  Skipping musk_1 as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,705 [MainThread  ] [WARNI]  Skipping musk_2 as test/train split already exists in output h5 file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-06 23:29:39,717 [MainThread  ] [WARNI]  Skipping nursery as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,736 [MainThread  ] [WARNI]  Skipping oocytes_merluccius_nucleus_4d as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,754 [MainThread  ] [WARNI]  Skipping oocytes_merluccius_states_2f as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,779 [MainThread  ] [WARNI]  Skipping oocytes_trisopterus_nucleus_2f as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,799 [MainThread  ] [WARNI]  Skipping oocytes_trisopterus_states_5b as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,819 [MainThread  ] [WARNI]  Skipping optical as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,838 [MainThread  ] [WARNI]  Skipping ozone as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,871 [MainThread  ] [WARNI]  Skipping page_blocks as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,889 [MainThread  ] [WARNI]  Skipping parkinsons as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,910 [MainThread  ] [WARNI]  Skipping pendigits as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,929 [MainThread  ] [WARNI]  Skipping pima as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,951 [MainThread  ] [WARNI]  Skipping pittsburg_bridges_MATERIAL as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,970 [MainThread  ] [WARNI]  Skipping pittsburg_bridges_REL_L as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:39,989 [MainThread  ] [WARNI]  Skipping pittsburg_bridges_SPAN as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,017 [MainThread  ] [WARNI]  Skipping pittsburg_bridges_TYPE as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,034 [MainThread  ] [WARNI]  Skipping pittsburg_bridges_T_OR_D as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,050 [MainThread  ] [WARNI]  Skipping planning as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,065 [MainThread  ] [WARNI]  Skipping plant_margin as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,082 [MainThread  ] [WARNI]  Skipping plant_shape as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,099 [MainThread  ] [WARNI]  Skipping plant_texture as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,111 [MainThread  ] [WARNI]  Skipping post_operative as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,132 [MainThread  ] [WARNI]  Skipping primary_tumor as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,157 [MainThread  ] [WARNI]  Skipping ringnorm as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,181 [MainThread  ] [WARNI]  Skipping seeds as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,202 [MainThread  ] [WARNI]  Skipping semeion as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,229 [MainThread  ] [WARNI]  Skipping soybean as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,255 [MainThread  ] [WARNI]  Skipping spambase as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,282 [MainThread  ] [WARNI]  Skipping spect as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,307 [MainThread  ] [WARNI]  Skipping spectf as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,328 [MainThread  ] [WARNI]  Skipping statlog_australian_credit as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,352 [MainThread  ] [WARNI]  Skipping statlog_german_credit as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,374 [MainThread  ] [WARNI]  Skipping statlog_heart as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,390 [MainThread  ] [WARNI]  Skipping statlog_image as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,419 [MainThread  ] [WARNI]  Skipping statlog_landsat as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,442 [MainThread  ] [WARNI]  Skipping statlog_shuttle as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,467 [MainThread  ] [WARNI]  Skipping statlog_vehicle as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,491 [MainThread  ] [WARNI]  Skipping steel_plates as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,516 [MainThread  ] [WARNI]  Skipping synthetic_control as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,537 [MainThread  ] [WARNI]  Skipping teaching as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,555 [MainThread  ] [WARNI]  Skipping thyroid as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,577 [MainThread  ] [WARNI]  Skipping tic_tac_toe as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,589 [MainThread  ] [WARNI]  Skipping titanic as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,601 [MainThread  ] [WARNI]  Skipping trains as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,618 [MainThread  ] [WARNI]  Skipping twonorm as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,640 [MainThread  ] [WARNI]  Skipping vertebral_column_2clases as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,657 [MainThread  ] [WARNI]  Skipping vertebral_column_3clases as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,677 [MainThread  ] [WARNI]  Skipping wall_following as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,702 [MainThread  ] [WARNI]  Skipping waveform as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,720 [MainThread  ] [WARNI]  Skipping waveform_noise as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,737 [MainThread  ] [WARNI]  Skipping wine as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,757 [MainThread  ] [WARNI]  Skipping wine_quality_red as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,774 [MainThread  ] [WARNI]  Skipping wine_quality_white as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,797 [MainThread  ] [WARNI]  Skipping yeast as test/train split already exists in output h5 file.\n",
      "2018-03-06 23:29:40,815 [MainThread  ] [WARNI]  Skipping zoo as test/train split already exists in output h5 file.\n"
     ]
    }
   ],
   "source": [
    "dts_names_list, dts_names_list_full_path = data.list_datasets(hdf5_io=input_io, hdf5_group='delgado_datasets/')\n",
    "split_dts_list = data.split_datasets(hdf5_in=input_io, hdf5_out=out_io, dataset_paths=dts_names_list_full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Run the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-27 15:09:26,093 [MainThread  ] [WARNI]  Estimator LogisticRegression already trained on abalone. Loading it from disk.\n",
      "2018-01-27 15:09:26,093 [MainThread  ] [WARNI]  Estimator LogisticRegression already trained on abalone. Loading it from disk.\n",
      "2018-01-27 15:09:26,096 [MainThread  ] [WARNI]  Estimator RidgeRegression already trained on abalone. Loading it from disk.\n",
      "2018-01-27 15:09:26,096 [MainThread  ] [WARNI]  Estimator RidgeRegression already trained on abalone. Loading it from disk.\n",
      "2018-01-27 15:09:26,099 [MainThread  ] [WARNI]  Estimator Lasso already trained on abalone. Loading it from disk.\n",
      "2018-01-27 15:09:26,099 [MainThread  ] [WARNI]  Estimator Lasso already trained on abalone. Loading it from disk.\n",
      "2018-01-27 15:09:26,102 [MainThread  ] [WARNI]  Estimator LassoLars already trained on abalone. Loading it from disk.\n",
      "2018-01-27 15:09:26,102 [MainThread  ] [WARNI]  Estimator LassoLars already trained on abalone. Loading it from disk.\n",
      "2018-01-27 15:09:26,107 [MainThread  ] [WARNI]  Estimator PassiveAggressiveClassifier already trained on abalone. Loading it from disk.\n",
      "2018-01-27 15:09:26,107 [MainThread  ] [WARNI]  Estimator PassiveAggressiveClassifier already trained on abalone. Loading it from disk.\n",
      "2018-01-27 15:09:26,127 [MainThread  ] [WARNI]  Preditions for abalone already exist in H5 database. Predictions will be loaded from the H5 database instead of generating new ones.Delete predictions from H5 databse if using previously made predictions is not desired behaviour.\n",
      "2018-01-27 15:09:26,127 [MainThread  ] [WARNI]  Preditions for abalone already exist in H5 database. Predictions will be loaded from the H5 database instead of generating new ones.Delete predictions from H5 databse if using previously made predictions is not desired behaviour.\n",
      "2018-01-27 15:09:26,149 [MainThread  ] [WARNI]  Estimator LogisticRegression already trained on acute_inflammation. Loading it from disk.\n",
      "2018-01-27 15:09:26,149 [MainThread  ] [WARNI]  Estimator LogisticRegression already trained on acute_inflammation. Loading it from disk.\n",
      "2018-01-27 15:09:26,152 [MainThread  ] [WARNI]  Estimator RidgeRegression already trained on acute_inflammation. Loading it from disk.\n",
      "2018-01-27 15:09:26,152 [MainThread  ] [WARNI]  Estimator RidgeRegression already trained on acute_inflammation. Loading it from disk.\n",
      "2018-01-27 15:09:26,154 [MainThread  ] [WARNI]  Estimator Lasso already trained on acute_inflammation. Loading it from disk.\n",
      "2018-01-27 15:09:26,154 [MainThread  ] [WARNI]  Estimator Lasso already trained on acute_inflammation. Loading it from disk.\n",
      "2018-01-27 15:09:26,156 [MainThread  ] [WARNI]  Estimator LassoLars already trained on acute_inflammation. Loading it from disk.\n",
      "2018-01-27 15:09:26,156 [MainThread  ] [WARNI]  Estimator LassoLars already trained on acute_inflammation. Loading it from disk.\n",
      "2018-01-27 15:09:26,159 [MainThread  ] [WARNI]  Estimator PassiveAggressiveClassifier already trained on acute_inflammation. Loading it from disk.\n",
      "2018-01-27 15:09:26,159 [MainThread  ] [WARNI]  Estimator PassiveAggressiveClassifier already trained on acute_inflammation. Loading it from disk.\n",
      "2018-01-27 15:09:26,181 [MainThread  ] [WARNI]  Preditions for acute_inflammation already exist in H5 database. Predictions will be loaded from the H5 database instead of generating new ones.Delete predictions from H5 databse if using previously made predictions is not desired behaviour.\n",
      "2018-01-27 15:09:26,181 [MainThread  ] [WARNI]  Preditions for acute_inflammation already exist in H5 database. Predictions will be loaded from the H5 database instead of generating new ones.Delete predictions from H5 databse if using previously made predictions is not desired behaviour.\n",
      "2018-01-27 15:09:26,200 [MainThread  ] [WARNI]  Estimator LogisticRegression already trained on acute_nephritis. Loading it from disk.\n",
      "2018-01-27 15:09:26,200 [MainThread  ] [WARNI]  Estimator LogisticRegression already trained on acute_nephritis. Loading it from disk.\n",
      "2018-01-27 15:09:26,206 [MainThread  ] [WARNI]  Estimator RidgeRegression already trained on acute_nephritis. Loading it from disk.\n",
      "2018-01-27 15:09:26,206 [MainThread  ] [WARNI]  Estimator RidgeRegression already trained on acute_nephritis. Loading it from disk.\n",
      "2018-01-27 15:09:26,208 [MainThread  ] [WARNI]  Estimator Lasso already trained on acute_nephritis. Loading it from disk.\n",
      "2018-01-27 15:09:26,208 [MainThread  ] [WARNI]  Estimator Lasso already trained on acute_nephritis. Loading it from disk.\n",
      "2018-01-27 15:09:26,210 [MainThread  ] [WARNI]  Estimator LassoLars already trained on acute_nephritis. Loading it from disk.\n",
      "2018-01-27 15:09:26,210 [MainThread  ] [WARNI]  Estimator LassoLars already trained on acute_nephritis. Loading it from disk.\n",
      "2018-01-27 15:09:26,212 [MainThread  ] [WARNI]  Estimator PassiveAggressiveClassifier already trained on acute_nephritis. Loading it from disk.\n",
      "2018-01-27 15:09:26,212 [MainThread  ] [WARNI]  Estimator PassiveAggressiveClassifier already trained on acute_nephritis. Loading it from disk.\n",
      "2018-01-27 15:09:26,230 [MainThread  ] [WARNI]  Preditions for acute_nephritis already exist in H5 database. Predictions will be loaded from the H5 database instead of generating new ones.Delete predictions from H5 databse if using previously made predictions is not desired behaviour.\n",
      "2018-01-27 15:09:26,230 [MainThread  ] [WARNI]  Preditions for acute_nephritis already exist in H5 database. Predictions will be loaded from the H5 database instead of generating new ones.Delete predictions from H5 databse if using previously made predictions is not desired behaviour.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training models on dataset: abalone. Total datasets processed: 0/3 ***\n",
      "*** Training models on dataset: acute_inflammation. Total datasets processed: 1/3 ***\n",
      "*** Training models on dataset: acute_nephritis. Total datasets processed: 2/3 ***\n"
     ]
    }
   ],
   "source": [
    "test_o.run(input_io_datasets_loc=dts_names_list_full_path[0:3], output_io_split_idx_loc=split_dts_list[0:3], modelling_strategies=instantiated_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze = AnalyseResults(hdf5_output_io=out_io, hdf5_input_io=input_io)\n",
    "observations = analyze.calculate_loss_all_datasets(input_h5_original_datasets_group='delgado_datasets/', \n",
    "                                    output_h5_predictions_group='experiments/predictions/', \n",
    "                                    metric='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>t_statistic</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso - LassoLars</td>\n",
       "      <td>-0.177322</td>\n",
       "      <td>0.859405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso - LogisticRegression</td>\n",
       "      <td>0.411066</td>\n",
       "      <td>0.681391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso - PassiveAggressiveClassifier</td>\n",
       "      <td>-0.253793</td>\n",
       "      <td>0.799873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso - RidgeRegression</td>\n",
       "      <td>-0.011886</td>\n",
       "      <td>0.990526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoLars - LogisticRegression</td>\n",
       "      <td>0.605498</td>\n",
       "      <td>0.545420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LassoLars - PassiveAggressiveClassifier</td>\n",
       "      <td>-0.097207</td>\n",
       "      <td>0.922643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoLars - RidgeRegression</td>\n",
       "      <td>0.164864</td>\n",
       "      <td>0.869190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression - PassiveAggressiveClassifier</td>\n",
       "      <td>-0.623414</td>\n",
       "      <td>0.533605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression - RidgeRegression</td>\n",
       "      <td>-0.422386</td>\n",
       "      <td>0.673121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PassiveAggressiveClassifier - RidgeRegression</td>\n",
       "      <td>0.242680</td>\n",
       "      <td>0.808461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pair  t_statistic   p_value\n",
       "0                                 Lasso - LassoLars    -0.177322  0.859405\n",
       "1                        Lasso - LogisticRegression     0.411066  0.681391\n",
       "2               Lasso - PassiveAggressiveClassifier    -0.253793  0.799873\n",
       "3                           Lasso - RidgeRegression    -0.011886  0.990526\n",
       "4                    LassoLars - LogisticRegression     0.605498  0.545420\n",
       "5           LassoLars - PassiveAggressiveClassifier    -0.097207  0.922643\n",
       "6                       LassoLars - RidgeRegression     0.164864  0.869190\n",
       "7  LogisticRegression - PassiveAggressiveClassifier    -0.623414  0.533605\n",
       "8              LogisticRegression - RidgeRegression    -0.422386  0.673121\n",
       "9     PassiveAggressiveClassifier - RidgeRegression     0.242680  0.808461"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test, t_test_df = analyze.t_test(observations)\n",
    "t_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sign test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>t_statistic</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso - LassoLars</td>\n",
       "      <td>0.901745</td>\n",
       "      <td>0.367192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso - LogisticRegression</td>\n",
       "      <td>0.087236</td>\n",
       "      <td>0.930484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso - PassiveAggressiveClassifier</td>\n",
       "      <td>-0.259871</td>\n",
       "      <td>0.794963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso - RidgeRegression</td>\n",
       "      <td>1.018365</td>\n",
       "      <td>0.308504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoLars - LogisticRegression</td>\n",
       "      <td>-0.508724</td>\n",
       "      <td>0.610946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LassoLars - PassiveAggressiveClassifier</td>\n",
       "      <td>-0.832874</td>\n",
       "      <td>0.404916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoLars - RidgeRegression</td>\n",
       "      <td>0.123967</td>\n",
       "      <td>0.901341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression - PassiveAggressiveClassifier</td>\n",
       "      <td>-0.403122</td>\n",
       "      <td>0.686858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression - RidgeRegression</td>\n",
       "      <td>0.641873</td>\n",
       "      <td>0.520955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PassiveAggressiveClassifier - RidgeRegression</td>\n",
       "      <td>0.955923</td>\n",
       "      <td>0.339111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pair  t_statistic   p_value\n",
       "0                                 Lasso - LassoLars     0.901745  0.367192\n",
       "1                        Lasso - LogisticRegression     0.087236  0.930484\n",
       "2               Lasso - PassiveAggressiveClassifier    -0.259871  0.794963\n",
       "3                           Lasso - RidgeRegression     1.018365  0.308504\n",
       "4                    LassoLars - LogisticRegression    -0.508724  0.610946\n",
       "5           LassoLars - PassiveAggressiveClassifier    -0.832874  0.404916\n",
       "6                       LassoLars - RidgeRegression     0.123967  0.901341\n",
       "7  LogisticRegression - PassiveAggressiveClassifier    -0.403122  0.686858\n",
       "8              LogisticRegression - RidgeRegression     0.641873  0.520955\n",
       "9     PassiveAggressiveClassifier - RidgeRegression     0.955923  0.339111"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_test, sign_test_df = analyze.sign_test(observations)\n",
    "sign_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-test with bonferroni correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso - LassoLars</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso - LogisticRegression</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso - PassiveAggressiveClassifier</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso - RidgeRegression</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoLars - LogisticRegression</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LassoLars - PassiveAggressiveClassifier</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoLars - RidgeRegression</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression - PassiveAggressiveClassifier</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression - RidgeRegression</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PassiveAggressiveClassifier - RidgeRegression</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pair  p_value\n",
       "0                                 Lasso - LassoLars      1.0\n",
       "1                        Lasso - LogisticRegression      1.0\n",
       "2               Lasso - PassiveAggressiveClassifier      1.0\n",
       "3                           Lasso - RidgeRegression      1.0\n",
       "4                    LassoLars - LogisticRegression      1.0\n",
       "5           LassoLars - PassiveAggressiveClassifier      1.0\n",
       "6                       LassoLars - RidgeRegression      1.0\n",
       "7  LogisticRegression - PassiveAggressiveClassifier      1.0\n",
       "8              LogisticRegression - RidgeRegression      1.0\n",
       "9     PassiveAggressiveClassifier - RidgeRegression      1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test_bonferroni, t_test_bonferroni_df = analyze.t_test_with_bonferroni_correction(observations)\n",
    "t_test_bonferroni_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wilcoxon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>statistic</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso - LassoLars</td>\n",
       "      <td>1520.0</td>\n",
       "      <td>2.470469e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso - LogisticRegression</td>\n",
       "      <td>3535.0</td>\n",
       "      <td>6.875244e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso - PassiveAggressiveClassifier</td>\n",
       "      <td>2364.0</td>\n",
       "      <td>6.010731e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso - RidgeRegression</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1.517763e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LassoLars - LogisticRegression</td>\n",
       "      <td>3064.0</td>\n",
       "      <td>1.051234e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LassoLars - PassiveAggressiveClassifier</td>\n",
       "      <td>1947.0</td>\n",
       "      <td>6.490607e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LassoLars - RidgeRegression</td>\n",
       "      <td>3249.0</td>\n",
       "      <td>2.534600e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression - PassiveAggressiveClassifier</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>1.197243e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression - RidgeRegression</td>\n",
       "      <td>2969.0</td>\n",
       "      <td>6.200856e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PassiveAggressiveClassifier - RidgeRegression</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>8.680879e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               pair  statistic       p_value\n",
       "0                                 Lasso - LassoLars     1520.0  2.470469e-07\n",
       "1                        Lasso - LogisticRegression     3535.0  6.875244e-01\n",
       "2               Lasso - PassiveAggressiveClassifier     2364.0  6.010731e-04\n",
       "3                           Lasso - RidgeRegression     2018.0  1.517763e-05\n",
       "4                    LassoLars - LogisticRegression     3064.0  1.051234e-01\n",
       "5           LassoLars - PassiveAggressiveClassifier     1947.0  6.490607e-06\n",
       "6                       LassoLars - RidgeRegression     3249.0  2.534600e-01\n",
       "7  LogisticRegression - PassiveAggressiveClassifier     1190.0  1.197243e-05\n",
       "8              LogisticRegression - RidgeRegression     2969.0  6.200856e-02\n",
       "9     PassiveAggressiveClassifier - RidgeRegression     1971.0  8.680879e-06"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilcoxon_test, wilcoxon_test_df = analyze.wilcoxon_test(observations)\n",
    "wilcoxon_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Friedman test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74.35786</td>\n",
       "      <td>2.724079e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   statistic       p_value\n",
       "0   74.35786  2.724079e-15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friedman_test, friedman_test_df = analyze.friedman_test(observations)\n",
    "friedman_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nemenyi test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        ,  0.96311003,  0.99972355,  0.99995087,  0.93743453],\n",
       "       [ 0.96311003, -1.        ,  0.98917175,  0.93329701,  0.99997031],\n",
       "       [ 0.99972355,  0.98917175, -1.        ,  0.99801612,  0.97694221],\n",
       "       [ 0.99995087,  0.93329701,  0.99801612, -1.        ,  0.89728878],\n",
       "       [ 0.93743453,  0.99997031,  0.97694221,  0.89728878, -1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nemeniy_test = analyze.nemenyi(observations)\n",
    "nemeniy_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
