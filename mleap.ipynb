{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_delgado.delgado_datasets import DownloadAndConvertDelgadoDatasets\n",
    "from mleap.data import Data\n",
    "from mleap.data.estimators import instantiate_default_estimators\n",
    "from mleap.experiments import TestOrchestrator\n",
    "from mleap.analyze_results import AnalyseResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Dataset Delgado_data\\molec-biol-protein-second has a different number of arff files\n"
     ]
    }
   ],
   "source": [
    "#load datasets as pandas DataFrame\n",
    "#each dataset needs to have metadata attached to it containing the following keys:\n",
    "# class_name: (string) name of column containing the column name in which the labels are stored\n",
    "# dataset_name: (string) name of the dataset\n",
    "delgado = DownloadAndConvertDelgadoDatasets()\n",
    "datasets, metadata = delgado.download_and_extract_datasets(verbose = False) #think about storing in hdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save the datasets in HDF5 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files io object needs to be used in test orch\n",
    "# returned object needs to be integrated in code\n",
    "data = Data()\n",
    "data.pandas_to_db(save_loc_hdf5='delgado_datasets/', datasets=datasets, \n",
    "                  dts_metadata=metadata, save_loc_hdd='data/delgado.hdf5') #return files io object\n",
    "input_io = data.open_hdf5('data/delgado.hdf5', mode='r')\n",
    "out_io = data.open_hdf5('data/experiments.hdf5', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Instantiate models and Test Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instantiated_models = instantiate_default_estimators(estimators=['all'])\n",
    "\n",
    "test_o = TestOrchestrator(hdf5_input_io=input_io, hdf5_output_io=out_io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dts_names_list, dts_names_list_full_path = data.list_datasets(hdf5_io=input_io, hdf5_group='delgado_datasets/')\n",
    "split_dts_list = data.split_datasets(hdf5_in=input_io, hdf5_out=out_io, dataset_paths=dts_names_list_full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Run the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training models on dataset: abalone. Total datasets processed: 0/3 ***\n",
      "*** Training models on dataset: acute_inflammation. Total datasets processed: 1/3 ***\n",
      "*** Training models on dataset: acute_nephritis. Total datasets processed: 2/3 ***\n"
     ]
    }
   ],
   "source": [
    "test_o.run(input_io_datasets_loc=dts_names_list_full_path[0:3], output_io_split_idx_loc=split_dts_list[0:3], modelling_strategies=instantiated_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******t-test******\n",
      "                                           pair  t_statistic  p_value\n",
      "0      BernoulliNaiveBayes - GaussianNaiveBayes         2.92     0.57\n",
      "1      BernoulliNaiveBayes - LogisticRegression         2.92     0.24\n",
      "2  BernoulliNaiveBayes - RandomForestClassifier         2.92     0.14\n",
      "3                     BernoulliNaiveBayes - SVC         2.92     0.16\n",
      "4       GaussianNaiveBayes - LogisticRegression         2.92     0.07\n",
      "5   GaussianNaiveBayes - RandomForestClassifier         2.92     0.09\n",
      "6                      GaussianNaiveBayes - SVC         2.92     0.09\n",
      "7   LogisticRegression - RandomForestClassifier         2.92     0.20\n",
      "8                      LogisticRegression - SVC         2.92     0.14\n",
      "9                  RandomForestClassifier - SVC         2.92     0.35\n"
     ]
    }
   ],
   "source": [
    "analyze = AnalyseResults(hdf5_output_io=out_io, hdf5_input_io=input_io)\n",
    "errors = analyze.calculate_loss_all_datasets(input_h5_original_datasets_group='delgado_datasets/', \n",
    "                                    output_h5_predictions_group='experiments/predictions/', \n",
    "                                    metric='mean_squared_error')\n",
    "\n",
    "t_test, t_test_df = analyze.perform_t_test(errors)\n",
    "print('******t-test******')\n",
    "print(t_test_df)\n",
    "\n",
    "# sign_test, sign_test_df = analyze.perform_sign_test()\n",
    "# print('******sign test******')\n",
    "# print(sign_test_df)\n",
    "\n",
    "# t_test_bonferroni, t_test_bonferroni_df = analyze.perform_t_test_with_bonferroni_correction()\n",
    "# print('******t-test bonferroni correction******')\n",
    "# print(t_test_bonferroni_df)\n",
    "# wilcoxon_test, wilcoxon_test_df = analyze.perform_wilcoxon()\n",
    "# print('******Wilcoxon test******')\n",
    "# print(wilcoxon_test_df)\n",
    "\n",
    "# friedman_test, friedman_test_df = analyze.perform_friedman_test()\n",
    "# print('******Friedman test******')\n",
    "# print(friedman_test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
