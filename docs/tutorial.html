

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Tutorial &mdash; mlaut 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Modules" href="modules.html" />
    <link rel="prev" title="Description of the project" href="project.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> mlaut
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="project.html">Description of the project</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#basic-usage">Basic Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mlaut-large-scale-ml-benchmarking-study">MLAUT Large Scale ML Benchmarking Study</a></li>
<li class="toctree-l2"><a class="reference internal" href="#docker-implementation">Docker Implementation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">Modules</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">mlaut</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Tutorial</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/tutorial.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="tutorial">
<h1>Tutorial<a class="headerlink" href="#tutorial" title="Permalink to this headline">¶</a></h1>
<div class="section" id="basic-usage">
<h2>Basic Usage<a class="headerlink" href="#basic-usage" title="Permalink to this headline">¶</a></h2>
<p>The code below will help you get started with mlaut.</p>
<p>The following Jupyter Notebook contains the code used below.</p>
<p><a class="reference download internal" download="" href="_downloads/095f4a8757ebcf11664cbc501447f7f7/mlaut_Basic_Usage.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">mlaut_Basic_Usage.ipynb</span></code></a>.</p>
<p><strong>1. Establish hooks to the database that stores the data for the experiments.</strong></p>
<p>The enclosed code can be used as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">Data</span><span class="p">()</span>
<span class="n">input_io</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">open_hdf5</span><span class="p">(</span><span class="s1">&#39;data/delgado.hdf5&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;a&#39;</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name"><cite>input_io</cite>:</th><td class="field-body">hook to the input HDF5 database file</td>
</tr>
<tr class="field-even field"><th class="field-name"><cite>out_io</cite>:</th><td class="field-body">hook to the output HDF5 database file</td>
</tr>
</tbody>
</table>
<p><strong>2. Split the datasets in train and test.</strong></p>
<p>After the hooks are created we can proceed to splitting the data in test and training.</p>
<p>Unless otherwise specified we use <img class="math" src="_images/math/82eb6a8598f40a61ac1119381011ca68b107c28c.png" alt="\dfrac{2}{3}"/> of the data for training and <img class="math" src="_images/math/6585ee00746995b084974ed52ca69d62911ad801.png" alt="\dfrac{1}{3}"/> for testing. We do not change or move the original data in this process. Instead we store the train/test indices in a separate HDF5 database.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dts_names_list</span><span class="p">,</span> <span class="n">dts_names_list_full_path</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">list_datasets</span><span class="p">(</span><span class="n">hdf5_io</span><span class="o">=</span><span class="n">input_io</span><span class="p">,</span> <span class="n">hdf5_group</span><span class="o">=</span><span class="s1">&#39;delgado_datasets/&#39;</span><span class="p">)</span>
<span class="n">split_dts_list</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">split_datasets</span><span class="p">(</span><span class="n">hdf5_in</span><span class="o">=</span><span class="n">input_io</span><span class="p">,</span> <span class="n">hdf5_out</span><span class="o">=</span><span class="n">out_io</span><span class="p">,</span> <span class="n">dataset_paths</span><span class="o">=</span><span class="n">dts_names_list_full_path</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name"><cite>dts_names_list</cite>:</th><td class="field-body">names of the datasets saved inside the HDF5 file</td>
</tr>
<tr class="field-even field"><th class="field-name" colspan="2"><cite>dts_names_list_full_path</cite>:</th></tr>
<tr class="field-even field"><td>&#160;</td><td class="field-body">full path to the datasets inside the HDF5 database</td>
</tr>
<tr class="field-odd field"><th class="field-name"><cite>split_dts_list</cite>:</th><td class="field-body">path to the train/test indices of the split datasets</td>
</tr>
</tbody>
</table>
<p><strong>3. Define the estimators.</strong></p>
<p>For the puposes of the basic demo we show how the standard set of estimaots that come with MLAUT can be used for running the experiments.</p>
<p>In the code example below we enumerate by name the estimators that we wish to use in the study. This will provide instances of MLAUT estimators with the built in defaults.</p>
<p>For more advanced used cases pleaes refer to <a class="reference download internal" download="" href="_downloads/4e0f9954c1608708df3961549676293a/mlaut-Advanced_Usage-generic_estimators.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">mlaut-Advanced_Usage-generic_estimators.ipynb</span></code></a> and <a class="reference download internal" download="" href="_downloads/070d181990844fd88713e5724147e92c/mlaut-Advanced_Usage-hyperparameters.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">mlaut-Advanced_Usage-hyperparameters.ipynb</span></code></a> which show how the user can easily change the hyper paramemeter defaults or define a completely new estimator object.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">est</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;RandomForestClassifier&#39;</span><span class="p">,</span><span class="s1">&#39;BaggingClassifier&#39;</span><span class="p">,</span><span class="s1">&#39;GradientBoostingClassifier&#39;</span><span class="p">,</span><span class="s1">&#39;SVC&#39;</span><span class="p">,</span><span class="s1">&#39;GaussianNaiveBayes&#39;</span><span class="p">,</span><span class="s1">&#39;BernoulliNaiveBayes&#39;</span><span class="p">,</span><span class="s1">&#39;NeuralNetworkDeepClassifier&#39;</span><span class="p">,</span><span class="s1">&#39;PassiveAggressiveClassifier&#39;</span><span class="p">,</span><span class="s1">&#39;BaselineClassifier&#39;</span><span class="p">]</span>
<span class="n">estimators</span> <span class="o">=</span> <span class="n">instantiate_default_estimators</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">est</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name"><cite>estimators</cite>:</th><td class="field-body">array of <code class="docutils literal notranslate"><span class="pre">mlaut</span></code> estimators</td>
</tr>
</tbody>
</table>
<p><strong>4. Run the experiments.</strong></p>
<p>The final step is to run the experiments by invoking the <code class="docutils literal notranslate"><span class="pre">run()</span></code> method.</p>
<p>This step could take a substantial amount of time depending on the number and size of datasets and the number of estimators that we wish to train.</p>
<p>All trained estimators are saved on the HDD.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">orchest</span> <span class="o">=</span> <span class="n">Orchestrator</span><span class="p">(</span><span class="n">hdf5_input_io</span><span class="o">=</span><span class="n">input_io</span><span class="p">,</span> <span class="n">hdf5_output_io</span><span class="o">=</span><span class="n">out_io</span><span class="p">,</span> <span class="n">dts_names</span><span class="o">=</span><span class="n">dts_names_list</span><span class="p">,</span>
                 <span class="n">original_datasets_group_h5_path</span><span class="o">=</span><span class="s1">&#39;delgado_datasets/&#39;</span><span class="p">)</span>
<span class="n">orchest</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">modelling_strategies</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p>One of the key feautres of the package is to allow for the experiment to resume in case of a crash or interruption. If this happens, the user would simply need to re-run the code above. Unless the <cite>override_saved_models=True</cite> flag was set the orchestrator will skip all estimators that were trained sucessfully. This would allow the user to continue from the point where the experiments were stopped.</p>
<p><strong>5. Make predictions on the test sets.</strong></p>
<p>After the estimators are trained the user needs to use them in order to make predictions on the test sets which will be used subsequently for performing statistical tests.</p>
<p>The predictions of the estimators are saved in the input HDF5 database file a hook to which was created earlier.</p>
<p>Unless the <cite>override=False</cite> flag was set MLAUT will not override predictions that were previously stored in the database.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">orchest</span><span class="o">.</span><span class="n">predict_all</span><span class="p">(</span><span class="n">trained_models_dir</span><span class="o">=</span><span class="s1">&#39;data/trained_models&#39;</span><span class="p">,</span> <span class="n">estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>6. Analyze results.</strong></p>
<p>The last step in the pipeline is to analyze the results of the experiments.</p>
<p>The <cite>AnalyseResults</cite> class takes as inputs the two database files and the loss metric that will be used to compute the prediction errors.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">analyze</span> <span class="o">=</span> <span class="n">AnalyseResults</span><span class="p">(</span><span class="n">hdf5_output_io</span><span class="o">=</span><span class="n">out_io</span><span class="p">,</span> 
                         <span class="n">hdf5_input_io</span><span class="o">=</span><span class="n">input_io</span><span class="p">,</span>
                         <span class="n">input_h5_original_datasets_group</span><span class="o">=</span><span class="s1">&#39;delgado_datasets/&#39;</span><span class="p">,</span> 
                         <span class="n">output_h5_predictions_group</span><span class="o">=</span><span class="s1">&#39;experiments/predictions/&#39;</span><span class="p">)</span>
<span class="n">score_accuracy</span> <span class="o">=</span> <span class="n">ScoreAccuracy</span><span class="p">()</span>


<span class="p">(</span><span class="n">errors_per_estimator</span><span class="p">,</span> 
 <span class="n">errors_per_dataset_per_estimator</span><span class="p">,</span> 
 <span class="n">errors_per_dataset_per_estimator_df</span><span class="p">)</span> <span class="o">=</span> <span class="n">analyze</span><span class="o">.</span><span class="n">prediction_errors</span><span class="p">(</span><span class="n">score_accuracy</span><span class="p">,</span> <span class="n">estimators</span><span class="p">)</span>
</pre></div>
</div>
<p>The <cite>prediction_errors()</cite> method retuns two sets of results: <cite>errors_per_estimator</cite> dictionary which is used subsequently in further statistical tests and <cite>errors_per_dataset_per_estimator_df</cite> which is a dataframe with the loss of each estimator on each dataset which can be examined directly by the user.</p>
<p>The <cite>errors_per_estimator</cite> result can be used as input to the following functions to perform the different statistical tests supported by <code class="docutils literal notranslate"><span class="pre">mlaut</span></code>.</p>
<ul class="simple">
<li><code class="xref py py-meth docutils literal notranslate"><span class="pre">mlaut.analyze_results.analyze_results.calculate_average_std()</span></code></li>
<li><code class="xref py py-meth docutils literal notranslate"><span class="pre">mlaut.analyze_results.analyze_results.cohens_d()</span></code></li>
<li><code class="xref py py-meth docutils literal notranslate"><span class="pre">mlaut.analyze_results.analyze_results.t_test()</span></code></li>
<li><code class="xref py py-meth docutils literal notranslate"><span class="pre">mlaut.analyze_results.analyze_results.sign_test()</span></code></li>
<li><code class="xref py py-meth docutils literal notranslate"><span class="pre">mlaut.analyze_results.analyze_results.t_test_with_bonferroni_correction()</span></code></li>
<li><code class="xref py py-meth docutils literal notranslate"><span class="pre">mlaut.analyze_results.analyze_results.wilcoxon_test()</span></code></li>
<li><code class="xref py py-meth docutils literal notranslate"><span class="pre">mlaut.analyze_results.analyze_results.ranksum_test()</span></code></li>
<li><code class="xref py py-meth docutils literal notranslate"><span class="pre">mlaut.analyze_results.analyze_results.friedman_test()</span></code></li>
<li><code class="xref py py-meth docutils literal notranslate"><span class="pre">mlaut.analyze_results.analyze_results.nemenyi()</span></code></li>
</ul>
<p>Please refer to <a class="reference internal" href="analyze_results.html#analyze-results"><span class="std std-ref">Analyze Results</span></a> for additional information about their use.</p>
</div>
<div class="section" id="mlaut-large-scale-ml-benchmarking-study">
<h2>MLAUT Large Scale ML Benchmarking Study<a class="headerlink" href="#mlaut-large-scale-ml-benchmarking-study" title="Permalink to this headline">¶</a></h2>
<p>We used <code class="docutils literal notranslate"><span class="pre">mlaut</span></code> to perform a large scale benchmarking study for a number of machine learning models. In doing so we recreated and expanded a previous paper (<a class="reference internal" href="#fernandez-delgado-we-2014" id="id1">[FDCBA14]</a>).</p>
<p>The code for our study can be downloaded from the following link <a class="reference download internal" download="" href="_downloads/3bd09a2295737060d11f651449eda77a/mlaut_study.zip"><code class="xref download docutils literal notranslate"><span class="pre">mlaut_study</span></code></a> and can also be used as an advanced tutorial and reference for using <code class="docutils literal notranslate"><span class="pre">mlaut</span></code>.</p>
<p id="bibtex-bibliography-tutorial-0"><table class="docutils citation" frame="void" id="fernandez-delgado-we-2014" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[FDCBA14]</a></td><td>Manuel Fernández-Delgado, Eva Cernadas, Senén Barro, and Dinani Amorim. Do we Need Hundreds of Classifiers to Solve Real World Classification Problems? <em>Journal of Machine Learning Research</em>, 15:3133–3181, 2014. URL: <a class="reference external" href="http://jmlr.org/papers/v15/delgado14a.html">http://jmlr.org/papers/v15/delgado14a.html</a>.</td></tr>
</tbody>
</table>
</p>
</div>
<div class="section" id="docker-implementation">
<h2>Docker Implementation<a class="headerlink" href="#docker-implementation" title="Permalink to this headline">¶</a></h2>
<p>Because the experiments can take quite a long time to complete we recommend running them inside a Docker container. To this end we have provided a Dockerfile that you can find <a class="reference external" href="../Docker/Dockerfile">here</a>.</p>
<p>First you should build the image:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ sudo docker build -t mlaut-train .
</pre></div>
</div>
<p>In order to run the experiments the user should mount a local directory to the <cite>/mlaut</cite> directory inside the container and execute a pre-defined script that sets up the experiments. Using the previous example from the benchmarking study:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ sudo docker run -ti -d --name mlaut-train -v <span class="s2">&quot;</span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span><span class="s2">:/mlaut&quot;</span> mlaut:latest /bin/sh -c <span class="s1">&#39;python MLAUT_study.py&#39;</span>
</pre></div>
</div>
<p>For further information about using Docker please refer to its <a class="reference external" href="https://www.docker.com/">documentation</a>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="modules.html" class="btn btn-neutral float-right" title="Modules" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="project.html" class="btn btn-neutral" title="Description of the project" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Viktor Kazakov

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
    

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>