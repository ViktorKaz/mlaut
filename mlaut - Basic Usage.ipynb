{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from download_delgado.delgado_datasets import DownloadAndConvertDelgadoDatasets\n",
    "from mlaut.data import Data\n",
    "from mlaut.estimators.estimators import instantiate_default_estimators\n",
    "from mlaut.experiments import Orchestrator\n",
    "from mlaut.analyze_results import AnalyseResults\n",
    "from download_delgado.delgado_datasets import DownloadAndConvertDelgadoDatasets\n",
    "from mlaut.analyze_results.scores import ScoreAccuracy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLAUT is a modelling and workflow toolbox in python, written with the aim of simplifying large scale benchmarking of machine learning strategies, e.g., validation, evaluation and comparison with respect to predictive/task-specific performance or runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this basis use case example we will show the most simple MLAUT workflow.\n",
    "\n",
    "For the purposes of this demonstration we will assume that the user has already stored the data needed for the experiments in a HDF5 database. Saving the data is not part of the core MLAUT workflow and is therefore omitted for the purposes of this this demonstration. \n",
    "\n",
    "Please refer to the advanced use case demos for examples how this can be done.\n",
    "\n",
    "the diagram below sketches the typical MLAUT workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/workflow.png?2\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below provides hooks to the input and output database objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()\n",
    "input_io = data.open_hdf5('data/delgado.hdf5', mode='a')\n",
    "out_io = data.open_hdf5('data/classification.hdf5', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`input_io`: hook to the input HDF5 database file <br>\n",
    "`out_io`:  hook to the output HDF5 database file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Split datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the hooks are created we can proceed to splitting the data in test and training. \n",
    "\n",
    "Unless otherwise specified we use $\\dfrac{2}{3}$ of the data for training and $\\dfrac{1}{3}$ for testing. We do not change or move the original data in this process. Instead we store the train/test indices in a separate HDF5 database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dts_names_list, dts_names_list_full_path = data.list_datasets(hdf5_io=input_io, hdf5_group='delgado_datasets/')\n",
    "split_dts_list = data.split_datasets(hdf5_in=input_io, hdf5_out=out_io, dataset_paths=dts_names_list_full_path, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dts_names_list`: names of the datasets saved inside the HDF5 file <br>\n",
    "`dts_names_list_full_path`: full path to the datasets inside the HDF5 database <br>\n",
    "`split_dts_list`: path to the train/test indices of the split datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the puposes of the basic demo we show how the standard set of estimaots that come with MLAUT can be used for running the experiments. \n",
    "\n",
    "In the code example below we enumerate by name the estimators that we wish to use in the study. This will provide instances of MLAUT estimators with the built in defaults.\n",
    "\n",
    "For more advanced used cases pleaes refer to the Advanced Usage - Example 1 and Example 2. The user can easily change the hyper paramemeter defaults or define a completely new estimator object ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = ['RandomForestClassifier','BaggingClassifier','GradientBoostingClassifier','SVC','GaussianNaiveBayes','BernoulliNaiveBayes','NeuralNetworkDeepClassifier','PassiveAggressiveClassifier','BaselineClassifier']\n",
    "estimators = instantiate_default_estimators(estimators=est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`estimators`: array of MLAUT estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to run the experiments by invoking the `run()` method.\n",
    "\n",
    "This step could take a substantial amount of time depending on the number and size of datasets and the number of estimators that we wish to train.\n",
    "\n",
    "All trained estimators are saved on the HDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-02 22:19:56,602 [MainThread  ] [INFO ]  Estimator RandomForestClassifier already trained on abalone. Skipping it.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Random_Forest_Classifier' object has no attribute '_trained_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c5bfe369dddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m orchest = Orchestrator(hdf5_input_io=input_io, hdf5_output_io=out_io, dts_names=dts_names_list,\n\u001b[1;32m      2\u001b[0m                  original_datasets_group_h5_path='delgado_datasets/')\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0morchest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelling_strategies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/media/viktor/Data/PhD/mlaut/mlaut/experiments/orchestrator.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, modelling_strategies, override_saved_models, verbose, predict_on_runtime, override_predictions)\u001b[0m\n\u001b[1;32m    123\u001b[0m                                             \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdts_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                                             \u001b[0moverride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_predictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                                             verbose=verbose)\n\u001b[0m\u001b[1;32m    126\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0;31m#preprocess data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/viktor/Data/PhD/mlaut/mlaut/experiments/orchestrator.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, modelling_strategy, X_test, dataset_name, override, verbose)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mverbose\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0mprints\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwarning\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \"\"\"\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mtrained_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelling_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mname_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/viktor/Data/PhD/mlaut/mlaut/estimators/mlaut_estimator.py\u001b[0m in \u001b[0;36mget_trained_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trained_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# def predict(self, X):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Random_Forest_Classifier' object has no attribute '_trained_model'"
     ]
    }
   ],
   "source": [
    "orchest = Orchestrator(hdf5_input_io=input_io, hdf5_output_io=out_io, dts_names=dts_names_list,\n",
    "                 original_datasets_group_h5_path='delgado_datasets/')\n",
    "orchest.run(modelling_strategies=estimators, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the key feautres of the package is to allow for the experiment to resume in case of a crash or interruption. If this happens, the user would simply need to re-run the code above. Unless the `override_saved_models=True` flag was set the orchestrator will skip all estimators that were trained sucessfully. This would allow the user to continue from the point where the experiments were stopped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Make predictions on the test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the estimators are trained the user needs to use them in order to make predictions on the test sets which will be used subsequently for performing statistical tests.\n",
    "\n",
    "The predictions of the estimators are saved in the input HDF5 database file a hook to which was created earlier.\n",
    "\n",
    "Unless the `override=False` flag was set MLAUT will not override predictions that were previously stored in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orchest.predict_all(trained_models_dir='data/trained_models', estimators=estimators, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Analyze the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step in the pipeline is to analyze the results of the experiments.\n",
    "\n",
    "The `AnalyseResults` class takes as inputs the two database files and the loss metric that will be used to compute the prediction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze = AnalyseResults(hdf5_output_io=out_io, \n",
    "                         hdf5_input_io=input_io,\n",
    "                         input_h5_original_datasets_group='delgado_datasets/', \n",
    "                         output_h5_predictions_group='experiments/predictions/')\n",
    "score_accuracy = ScoreAccuracy()\n",
    "\n",
    "\n",
    "(errors_per_estimator, \n",
    " errors_per_dataset_per_estimator, \n",
    " errors_per_dataset_per_estimator_df) = analyze.prediction_errors(score_accuracy, estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `prediction_errors()` method retuns two sets of results: `errors_per_estimator` dictionary which is used subsequently in further statistical tests and `errors_per_dataset_per_estimator_df` which is a dataframe with the loss of each estimator on each dataset which can be examined directly by the user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show the results of the various statistical tests that are supported by MLAUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test, t_test_df = analyze.t_test(errors_per_estimator)\n",
    "t_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sign test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_test, sign_test_df = analyze.sign_test(errors_per_estimator)\n",
    "sign_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-test with bonferroni correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_bonferroni_df = analyze.t_test_with_bonferroni_correction(errors_per_estimator)\n",
    "t_test_bonferroni_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wilcoxon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "wilcoxon_test, wilcoxon_test_df = analyze.wilcoxon_test(errors_per_estimator)\n",
    "wilcoxon_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Friedman test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friedman_test, friedman_test_df = analyze.friedman_test(errors_per_estimator)\n",
    "friedman_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nemenyi test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nemeniy_test = analyze.nemenyi(errors_per_estimator)\n",
    "nemeniy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nemeniy_test = analyze.nemenyi(errors_per_estimator)\n",
    "nemeniy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 5000)\n",
    "errors_per_dataset_per_estimator_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
